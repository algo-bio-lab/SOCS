{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "157d35ca",
   "metadata": {},
   "source": [
    "### Simple test notebook\n",
    "This notebook is a simple test of the functionality of the SOCS method with a very small dataset, to ensure that the software works properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d45acb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//broad/clearylab/Users/Peter/anaconda3/envs/myEnv/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as io\n",
    "from scipy import stats\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import squidpy as sq\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import math\n",
    "import sklearn\n",
    "import torch\n",
    "from unbalancedgw_f.vanilla_ugw_solver import log_ugw_sinkhorn_f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab49cae",
   "metadata": {},
   "source": [
    "We'll load in a very small sample from the two timepoints in the MERFISH mouse ovary datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "854d61ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_1 = sc.read_h5ad('adata_1_follicle.h5ad')\n",
    "adata_2 = sc.read_h5ad('adata_2_follicle.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7288a816",
   "metadata": {},
   "source": [
    "We'll obtain the dimensionally-reduced count tables $G^{(p)}_1$ and $G^{(p)}_2$, and the spatial location vectors $x_1$, $x_2$, $y_1$, and $y_2$, as defined in Eq. FILL IN in our manuscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "495ea479",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//broad/clearylab/Users/Peter/anaconda3/envs/myEnv/lib/python3.9/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: \u001b[1mThe TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12030. The TBB threading layer is disabled.\u001b[0m\n",
      "  warnings.warn(problem)\n"
     ]
    }
   ],
   "source": [
    "adata_concat= ad.concat([adata_1,adata_2])\n",
    "sc.pp.pca(adata_concat, random_state= 0,n_comps=30)\n",
    "adata_concat_1 = adata_concat[0:adata_1.shape[0],:]\n",
    "adata_concat_2 = adata_concat[adata_1.shape[0]:,:]\n",
    "G_p_1 = adata_concat_1.obsm['X_pca']\n",
    "G_p_2 = adata_concat_2.obsm['X_pca']\n",
    "x_1 = adata_concat_1.obsm['spatial'][:,0]\n",
    "y_1 = adata_concat_1.obsm['spatial'][:,1]\n",
    "x_2 = adata_concat_2.obsm['spatial'][:,0]\n",
    "y_2 = adata_concat_2.obsm['spatial'][:,1]\n",
    "xy_1 = np.stack([x_1,y_1],axis=1)\n",
    "xy_2 = np.stack([x_2,y_2],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fcc724",
   "metadata": {},
   "source": [
    "This cell computes the matrices $D_g$, $D_1$, and $D_2$, along with the normalization factors $f_1$ and $f_2$, as defined in Eq. FILL IN in our manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8711d394",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_g = np.ascontiguousarray(sklearn.metrics.pairwise.pairwise_distances(G_p_1,Y=G_p_2,metric='euclidean',n_jobs=1))\n",
    "D_1 = np.ascontiguousarray(sklearn.metrics.pairwise.pairwise_distances(xy_1,Y=xy_1,metric='euclidean',n_jobs=1))\n",
    "D_2 = np.ascontiguousarray(sklearn.metrics.pairwise.pairwise_distances(xy_2,Y=xy_2,metric='euclidean',n_jobs=1))\n",
    "f1 = (np.max(D_1)/np.max(D_g))**2\n",
    "f2 = (np.max(D_2)/np.max(D_g))**2\n",
    "nCells_1 = adata_1.shape[0]\n",
    "nCells_2 = adata_2.shape[0]\n",
    "p1 = np.ones([nCells_1,])/nCells_1\n",
    "p2 = np.ones([nCells_2,])/nCells_2\n",
    "D_g_torch = torch.tensor(D_g,dtype=torch.float64)\n",
    "D_1_torch = torch.tensor(D_1,dtype=torch.float64)\n",
    "D_2_torch = torch.tensor(D_2,dtype=torch.float64)\n",
    "p1_torch = torch.tensor(p1,dtype=torch.float64)\n",
    "p2_torch = torch.tensor(p2,dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fc1feb",
   "metadata": {},
   "source": [
    "Finally, we'll use the SOCS algorithm to estimate the trajectory mapping $T$ between the samples at $t_1$ and $t_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8ba6eb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.5\n",
    "eps = 2e-4\n",
    "rho1 = 5000.0\n",
    "rho2 = 5000.0\n",
    "T_torch, gamma = log_ugw_sinkhorn_f(p1_torch, D_1_torch/f1, p2_torch, D_2_torch/f2, D_g_torch, alpha, init=None, eps=eps,\n",
    "    rho=rho1, rho2=rho2,\n",
    "    nits_plan=30, tol_plan=1e-30,\n",
    "    nits_sinkhorn=10, tol_sinkhorn=1e-9,\n",
    "    two_outputs=False,print_per_iter=10,alt=0)\n",
    "\n",
    "T = T_socs_torch.numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
